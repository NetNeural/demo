# ðŸŽ¯ NetNeural MVP - Detailed User Stories & Task Breakdown

**Report Date**: August 12, 2025  
**Purpose**: Granular task breakdown for remaining 29% MVP work  
**Format**: User stories with acceptance criteria and implementation tasks  

---

## ðŸ“‹ Document Structure

This document breaks down each remaining epic into:
- **User Stories** (business value perspective)
- **Acceptance Criteria** (definition of done)
- **Technical Tasks** (specific implementation work)
- **Dependencies** (what needs to be done first)
- **Testing Requirements** (validation criteria)

---

## ðŸš§ Epic 1: Hierarchical Data Management (10% Remaining)

### **Story 1.1: Enhanced Entity Validation**
```
As a system administrator,
I want comprehensive validation on all entity data entry,
So that our database maintains data integrity and business rules.
```

**Why This Is Missing:**
Currently, basic validation exists but lacks business rule enforcement and advanced field validation.

**What's Wrong Now:**
- No email format validation for contact fields
- No phone number format checking
- Can create unlimited locations per subsidiary (no capacity limits)
- Bulk operations not available (users must add entities one by one)

**Acceptance Criteria:**
- [ ] Email addresses must follow RFC 5322 format
- [ ] Phone numbers must follow E.164 international format
- [ ] Subsidiaries can have maximum 50 locations (configurable)
- [ ] Locations can have maximum 20 departments (configurable)
- [ ] Bulk import/export works for all entity types

**Technical Tasks:**

**Task 1.1.1: Advanced Field Validation**
```bash
Files to Modify:
â”œâ”€â”€ account-manager/main.go
â”‚   â”œâ”€â”€ Add email validation using regexp
â”‚   â”œâ”€â”€ Add phone number validation
â”‚   â””â”€â”€ Add field length validation

â”œâ”€â”€ account-manager/validation/
â”‚   â”œâ”€â”€ email_validator.go (NEW)
â”‚   â”œâ”€â”€ phone_validator.go (NEW)
â”‚   â””â”€â”€ business_rules.go (NEW)

Implementation Details:
â”œâ”€â”€ Install validation library: go get github.com/go-playground/validator/v10
â”œâ”€â”€ Create custom validation tags
â”œâ”€â”€ Add validation middleware to API endpoints
â””â”€â”€ Return detailed validation errors to frontend

Effort: 2 days
Developer: 1 Backend
```

**Task 1.1.2: Business Rules Engine**
```bash
Files to Modify:
â”œâ”€â”€ account-manager/business_rules/
â”‚   â”œâ”€â”€ capacity_limits.go (NEW)
â”‚   â”œâ”€â”€ hierarchy_rules.go (NEW)
â”‚   â””â”€â”€ validation_engine.go (NEW)

â”œâ”€â”€ Database Schema:
â”‚   â”œâ”€â”€ ALTER TABLE subsidiaries ADD COLUMN max_locations INT DEFAULT 50
â”‚   â”œâ”€â”€ ALTER TABLE locations ADD COLUMN max_departments INT DEFAULT 20
â”‚   â””â”€â”€ CREATE INDEX idx_hierarchy_counts ON locations(subsidiary_id)

Implementation Details:
â”œâ”€â”€ Create configurable business rules
â”œâ”€â”€ Add pre-save validation hooks
â”œâ”€â”€ Implement capacity checking before entity creation
â””â”€â”€ Add admin interface for rule configuration

Effort: 3 days
Developer: 1 Backend
```

**Task 1.1.3: Bulk Import/Export System**
```bash
Files to Modify:
â”œâ”€â”€ account-manager/bulk/
â”‚   â”œâ”€â”€ csv_importer.go (NEW)
â”‚   â”œâ”€â”€ excel_exporter.go (NEW)
â”‚   â””â”€â”€ bulk_validator.go (NEW)

â”œâ”€â”€ origin-ui/src/components/bulk/
â”‚   â”œâ”€â”€ BulkImporter.tsx (NEW)
â”‚   â”œâ”€â”€ BulkExporter.tsx (NEW)
â”‚   â””â”€â”€ ImportProgress.tsx (NEW)

API Endpoints to Add:
â”œâ”€â”€ POST /api/entities/bulk-import
â”œâ”€â”€ GET /api/entities/bulk-export
â”œâ”€â”€ GET /api/entities/bulk-template
â””â”€â”€ GET /api/entities/import-status/:jobId

Implementation Details:
â”œâ”€â”€ CSV/Excel parsing with validation
â”œâ”€â”€ Background job processing for large imports
â”œâ”€â”€ Progress tracking and error reporting
â”œâ”€â”€ Template generation for proper format
â””â”€â”€ Rollback capability for failed imports

Effort: 5 days
Developer: 1 Backend + 1 Frontend
```

---

### **Story 1.2: Comprehensive Audit Trail**
```
As a compliance officer,
I want detailed change tracking for all entity modifications,
So that I can maintain audit compliance and investigate issues.
```

**Why This Is Missing:**
Basic audit logging exists but lacks detailed change tracking, user attribution, and rollback capabilities.

**What's Wrong Now:**
- Only logs "entity created/updated/deleted" without field-level changes
- No easy way to see what changed from old value to new value
- Cannot rollback changes if mistakes are made
- No audit reports for compliance

**Acceptance Criteria:**
- [ ] Track field-level changes (old value â†’ new value)
- [ ] Record user who made each change with timestamp
- [ ] Provide rollback capability for critical entities
- [ ] Generate audit reports for date ranges
- [ ] Export audit logs for compliance

**Technical Tasks:**

**Task 1.2.1: Enhanced Change Tracking**
```bash
Files to Modify:
â”œâ”€â”€ iot-common/audit/
â”‚   â”œâ”€â”€ change_tracker.go (NEW)
â”‚   â”œâ”€â”€ field_differ.go (NEW)
â”‚   â””â”€â”€ audit_logger.go (ENHANCE)

â”œâ”€â”€ Database Schema:
â”‚   â”œâ”€â”€ CREATE TABLE audit_changes (
â”‚   â”‚     id UUID PRIMARY KEY,
â”‚   â”‚     table_name VARCHAR(100),
â”‚   â”‚     record_id UUID,
â”‚   â”‚     field_name VARCHAR(100),
â”‚   â”‚     old_value TEXT,
â”‚   â”‚     new_value TEXT,
â”‚   â”‚     user_id UUID,
â”‚   â”‚     timestamp TIMESTAMP,
â”‚   â”‚     operation VARCHAR(20)
â”‚   â”‚   )
â”‚   â””â”€â”€ CREATE INDEX idx_audit_changes_record ON audit_changes(table_name, record_id)

Implementation Details:
â”œâ”€â”€ Implement before/after comparison logic
â”œâ”€â”€ JSON serialization for complex field changes
â”œâ”€â”€ Automatic trigger generation for all entity tables
â”œâ”€â”€ User context propagation to database layer
â””â”€â”€ Efficient storage for large text fields

Effort: 3 days
Developer: 1 Backend
```

**Task 1.2.2: Rollback System**
```bash
Files to Modify:
â”œâ”€â”€ account-manager/rollback/
â”‚   â”œâ”€â”€ rollback_engine.go (NEW)
â”‚   â”œâ”€â”€ snapshot_manager.go (NEW)
â”‚   â””â”€â”€ rollback_validator.go (NEW)

API Endpoints to Add:
â”œâ”€â”€ GET /api/entities/{id}/history
â”œâ”€â”€ POST /api/entities/{id}/rollback/{timestamp}
â”œâ”€â”€ GET /api/entities/{id}/snapshot/{timestamp}
â””â”€â”€ POST /api/entities/rollback/preview

Implementation Details:
â”œâ”€â”€ Create entity snapshots before major changes
â”œâ”€â”€ Validate rollback operations for dependencies
â”œâ”€â”€ Preview rollback changes before execution
â”œâ”€â”€ Rollback approval workflow for critical entities
â””â”€â”€ Cascade rollback handling for related entities

Effort: 4 days
Developer: 1 Backend
```

**Task 1.2.3: Audit Reporting Interface**
```bash
Files to Modify:
â”œâ”€â”€ origin-ui/src/components/audit/
â”‚   â”œâ”€â”€ AuditReportDashboard.tsx (NEW)
â”‚   â”œâ”€â”€ ChangeHistory.tsx (NEW)
â”‚   â”œâ”€â”€ AuditFilters.tsx (NEW)
â”‚   â””â”€â”€ AuditExporter.tsx (NEW)

Features to Implement:
â”œâ”€â”€ Date range filtering for audit reports
â”œâ”€â”€ User-specific change tracking
â”œâ”€â”€ Entity-specific audit trails
â”œâ”€â”€ Change visualization (before/after comparison)
â”œâ”€â”€ PDF/CSV export for compliance reports

Implementation Details:
â”œâ”€â”€ Advanced filtering and search capabilities
â”œâ”€â”€ Change diff visualization component
â”œâ”€â”€ Pagination for large audit datasets
â”œâ”€â”€ Real-time audit log updates
â””â”€â”€ Role-based audit data access

Effort: 3 days
Developer: 1 Frontend
```

---

## ðŸš§ Epic 2: Golioth IoT Integration (51% Remaining) - CRITICAL PATH

### **Story 2.1: Real IoT Device Connectivity**
```
As an IoT technician,
I want to connect real sensors through Golioth platform,
So that we can manage actual IoT deployments instead of mock data.
```

**Why This Is Missing:**
Currently the system only works with mock sensor data. No real IoT devices can be connected.

**What's Wrong Now:**
- All sensor data is generated by mock functions
- No way to provision real IoT devices
- Cannot connect to Golioth cloud platform
- No real-time data from actual sensors

**Acceptance Criteria:**
- [ ] Connect to Golioth Management API
- [ ] Provision real IoT devices with certificates
- [ ] Receive real sensor data through LightDB Stream
- [ ] Monitor device connectivity status
- [ ] Handle device offline/online events

**Technical Tasks:**

**Task 2.1.1: Golioth SDK Integration**
```bash
Files to Create:
â”œâ”€â”€ golioth-integration/
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ client/
â”‚   â”‚   â”œâ”€â”€ golioth_client.go
â”‚   â”‚   â”œâ”€â”€ auth_manager.go
â”‚   â”‚   â””â”€â”€ device_manager.go
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ device.go
â”‚   â”‚   â”œâ”€â”€ certificate.go
â”‚   â”‚   â””â”€â”€ stream_data.go
â”‚   â””â”€â”€ config/
â”‚       â”œâ”€â”€ golioth_config.go
â”‚       â””â”€â”€ environment.go

Dependencies to Add:
â”œâ”€â”€ go.mod: Add Golioth SDK
â”œâ”€â”€ docker-compose.yml: Add golioth-integration service
â”œâ”€â”€ .env: Add Golioth API credentials
â””â”€â”€ helm/: Add golioth-integration deployment

What This Solves:
â”œâ”€â”€ Establishes connection to Golioth cloud
â”œâ”€â”€ Provides authentication for device operations
â”œâ”€â”€ Creates foundation for all IoT functionality
â””â”€â”€ Enables real device management

Implementation Details:
â”œâ”€â”€ Install Golioth Go SDK
â”œâ”€â”€ Configure API authentication
â”œâ”€â”€ Create connection pooling for multiple devices
â”œâ”€â”€ Add error handling and retry logic
â”œâ”€â”€ Implement rate limiting for API calls

Effort: 1 week
Developer: 1 Senior Backend (IoT experience required)
```

**Task 2.1.2: Device Provisioning Workflow**
```bash
Files to Modify:
â”œâ”€â”€ golioth-integration/provisioning/
â”‚   â”œâ”€â”€ device_provisioner.go (NEW)
â”‚   â”œâ”€â”€ certificate_manager.go (NEW)
â”‚   â””â”€â”€ provisioning_workflow.go (NEW)

â”œâ”€â”€ origin-ui/src/components/devices/
â”‚   â”œâ”€â”€ DeviceProvisioning.tsx (NEW)
â”‚   â”œâ”€â”€ CertificateUpload.tsx (NEW)
â”‚   â””â”€â”€ ProvisioningStatus.tsx (NEW)

Database Changes:
â”œâ”€â”€ CREATE TABLE golioth_devices (
â”‚   â”‚   id UUID PRIMARY KEY,
â”‚   â”‚   golioth_device_id VARCHAR(255),
â”‚   â”‚   certificate_id VARCHAR(255),
â”‚   â”‚   device_name VARCHAR(255),
â”‚   â”‚   provisioning_status VARCHAR(50),
â”‚   â”‚   last_seen TIMESTAMP,
â”‚   â”‚   created_at TIMESTAMP
â”‚   )
â””â”€â”€ ALTER TABLE sensors ADD COLUMN golioth_device_id UUID

What This Solves:
â”œâ”€â”€ Allows adding real IoT devices to the system
â”œâ”€â”€ Manages device certificates and security
â”œâ”€â”€ Tracks device provisioning status
â””â”€â”€ Links Golioth devices to our sensor entities

API Endpoints to Add:
â”œâ”€â”€ POST /api/devices/provision
â”œâ”€â”€ GET /api/devices/provisioning-status/{id}
â”œâ”€â”€ PUT /api/devices/{id}/certificate
â”œâ”€â”€ DELETE /api/devices/{id}/deprovision
â””â”€â”€ GET /api/devices/available

Implementation Steps:
1. Create device provisioning API
2. Build certificate management system
3. Add provisioning UI workflow
4. Implement status tracking
5. Add device decommissioning

Effort: 1 week
Developer: 1 Backend + 1 Frontend
```

**Task 2.1.3: LightDB Stream Integration**
```bash
Files to Modify:
â”œâ”€â”€ golioth-integration/streaming/
â”‚   â”œâ”€â”€ lightdb_client.go (NEW)
â”‚   â”œâ”€â”€ stream_processor.go (NEW)
â”‚   â”œâ”€â”€ data_transformer.go (NEW)
â”‚   â””â”€â”€ real_time_updater.go (NEW)

â”œâ”€â”€ data-manager/ (MAJOR CHANGES)
â”‚   â”œâ”€â”€ Replace mock data generation
â”‚   â”œâ”€â”€ Add Golioth stream consumption
â”‚   â”œâ”€â”€ Add data validation for real sensors
â”‚   â””â”€â”€ Add real-time data pipeline

What This Solves:
â”œâ”€â”€ Replaces mock sensor data with real readings
â”œâ”€â”€ Provides real-time updates from actual sensors
â”œâ”€â”€ Enables live dashboard updates
â””â”€â”€ Supports historical data collection

Current Problem:
// Current mock data in UnifiedDashboard.tsx
const generateMockSensorReadings = () => {
  return Array.from({ length: 24 }, (_, i) => ({
    time: `${23 - i}:00`,
    value: Math.round(20 + Math.random() * 10)
  }));
};

New Implementation:
// Real data from Golioth LightDB Stream
const fetchRealSensorData = async (deviceId: string) => {
  const response = await fetch(`/api/golioth/devices/${deviceId}/stream`);
  return response.json();
};

Technical Implementation:
â”œâ”€â”€ WebSocket connection to LightDB Stream
â”œâ”€â”€ Data transformation from Golioth format to our schema
â”œâ”€â”€ Real-time database updates
â”œâ”€â”€ Conflict resolution for simultaneous updates
â”œâ”€â”€ Data validation and error handling

Effort: 1.5 weeks
Developer: 2 Backend developers
```

---

### **Story 2.2: IoT Pipeline Configuration**
```
As an IoT administrator,
I want to configure data processing pipelines for different sensor types,
So that I can customize how sensor data is processed and stored.
```

**Why This Is Missing:**
Currently there's no way to configure how sensor data flows through the system or apply custom processing rules.

**What's Wrong Now:**
- All sensor data processed the same way regardless of type
- No custom alerts or thresholds per sensor type
- Cannot route data to different destinations
- No way to transform data before storage

**Acceptance Criteria:**
- [ ] Visual pipeline editor for data flow
- [ ] Custom processing rules per sensor type
- [ ] Data routing to different storage/alert systems
- [ ] Pipeline testing and validation
- [ ] Pipeline monitoring and debugging

**Technical Tasks:**

**Task 2.2.1: Pipeline Configuration Engine**
```bash
Files to Create:
â”œâ”€â”€ pipeline-config/
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ engine/
â”‚   â”‚   â”œâ”€â”€ pipeline_engine.go
â”‚   â”‚   â”œâ”€â”€ rule_processor.go
â”‚   â”‚   â”œâ”€â”€ data_router.go
â”‚   â”‚   â””â”€â”€ transformation_engine.go
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”œâ”€â”€ pipeline.go
â”‚   â”‚   â”œâ”€â”€ rule.go
â”‚   â”‚   â””â”€â”€ transformation.go
â”‚   â””â”€â”€ handlers/
â”‚       â”œâ”€â”€ pipeline_handler.go
â”‚       â”œâ”€â”€ rule_handler.go
â”‚       â””â”€â”€ testing_handler.go

Database Schema:
â”œâ”€â”€ CREATE TABLE pipelines (
â”‚   â”‚   id UUID PRIMARY KEY,
â”‚   â”‚   name VARCHAR(255),
â”‚   â”‚   sensor_type VARCHAR(100),
â”‚   â”‚   configuration JSONB,
â”‚   â”‚   is_active BOOLEAN,
â”‚   â”‚   created_by UUID,
â”‚   â”‚   created_at TIMESTAMP
â”‚   )
â”œâ”€â”€ CREATE TABLE pipeline_rules (
â”‚   â”‚   id UUID PRIMARY KEY,
â”‚   â”‚   pipeline_id UUID,
â”‚   â”‚   rule_type VARCHAR(50),
â”‚   â”‚   conditions JSONB,
â”‚   â”‚   actions JSONB,
â”‚   â”‚   order_index INTEGER
â”‚   )
â””â”€â”€ CREATE TABLE pipeline_executions (
â”‚       id UUID PRIMARY KEY,
â”‚       pipeline_id UUID,
â”‚       input_data JSONB,
â”‚       output_data JSONB,
â”‚       execution_time_ms INTEGER,
â”‚       status VARCHAR(50),
â”‚       executed_at TIMESTAMP
â”‚     )

What This Solves:
â”œâ”€â”€ Configurable data processing per sensor type
â”œâ”€â”€ Custom business logic for different use cases
â”œâ”€â”€ Scalable rule engine for complex scenarios
â””â”€â”€ Audit trail for pipeline executions

Effort: 2 weeks
Developer: 1 Senior Backend
```

**Task 2.2.2: Visual Pipeline Editor**
```bash
Files to Create:
â”œâ”€â”€ origin-ui/src/components/pipelines/
â”‚   â”œâ”€â”€ PipelineEditor.tsx (NEW)
â”‚   â”œâ”€â”€ PipelineDiagram.tsx (NEW)
â”‚   â”œâ”€â”€ RuleBuilder.tsx (NEW)
â”‚   â”œâ”€â”€ TransformationEditor.tsx (NEW)
â”‚   â””â”€â”€ PipelineTestRunner.tsx (NEW)

Dependencies to Add:
â”œâ”€â”€ npm install react-flow-renderer (for visual pipeline editing)
â”œâ”€â”€ npm install monaco-editor (for rule/transformation editing)
â”œâ”€â”€ npm install react-json-editor-ajrm (for JSON configuration)

Features to Implement:
â”œâ”€â”€ Drag-and-drop pipeline component creation
â”œâ”€â”€ Visual data flow representation
â”œâ”€â”€ Rule condition builder (if/then/else logic)
â”œâ”€â”€ Data transformation editor
â”œâ”€â”€ Pipeline testing with sample data
â”œâ”€â”€ Real-time pipeline execution monitoring

What This Solves:
â”œâ”€â”€ Non-technical users can configure pipelines
â”œâ”€â”€ Visual representation makes complex flows understandable
â”œâ”€â”€ Testing prevents pipeline errors in production
â””â”€â”€ Monitoring helps debug pipeline issues

Example Pipeline Configuration:
```json
{
  "name": "Temperature Sensor Pipeline",
  "sensorType": "temperature",
  "steps": [
    {
      "type": "validation",
      "rules": {
        "minValue": -40,
        "maxValue": 85,
        "unit": "celsius"
      }
    },
    {
      "type": "transformation",
      "convert": "fahrenheit",
      "formula": "(celsius * 9/5) + 32"
    },
    {
      "type": "alert",
      "conditions": {
        "if": "value > 80",
        "then": "trigger_high_temp_alert"
      }
    },
    {
      "type": "storage",
      "destinations": ["timeseries_db", "data_lake"]
    }
  ]
}
```

Effort: 2 weeks
Developer: 1 Frontend + 1 Backend
```

---

### **Story 2.3: Device Health Monitoring**
```
As an IoT operations manager,
I want real-time monitoring of device connectivity and health,
So that I can proactively address device issues before they impact operations.
```

**Why This Is Missing:**
Currently no way to monitor if devices are actually online, offline, or having connectivity issues.

**What's Wrong Now:**
- Device status is just mock "online/offline" flags
- No connectivity quality metrics
- Cannot detect devices that are struggling with network issues
- No alerts when devices go offline unexpectedly

**Acceptance Criteria:**
- [ ] Real-time connectivity status for all devices
- [ ] Network quality metrics (signal strength, latency)
- [ ] Automatic offline device detection
- [ ] Connectivity alerts and notifications
- [ ] Historical connectivity reporting

**Technical Tasks:**

**Task 2.3.1: Device Heartbeat System**
```bash
Files to Modify:
â”œâ”€â”€ golioth-integration/monitoring/
â”‚   â”œâ”€â”€ heartbeat_monitor.go (NEW)
â”‚   â”œâ”€â”€ connectivity_tracker.go (NEW)
â”‚   â””â”€â”€ health_checker.go (NEW)

â”œâ”€â”€ alert-listener/ (ENHANCE)
â”‚   â”œâ”€â”€ Add connectivity alert rules
â”‚   â”œâ”€â”€ Add device offline detection
â”‚   â””â”€â”€ Add network quality alerts

Database Changes:
â”œâ”€â”€ CREATE TABLE device_heartbeats (
â”‚   â”‚   device_id UUID,
â”‚   â”‚   timestamp TIMESTAMP,
â”‚   â”‚   signal_strength INTEGER,
â”‚   â”‚   battery_level INTEGER,
â”‚   â”‚   network_latency_ms INTEGER,
â”‚   â”‚   data_usage_bytes BIGINT
â”‚   )
â”œâ”€â”€ CREATE TABLE connectivity_events (
â”‚   â”‚   id UUID PRIMARY KEY,
â”‚   â”‚   device_id UUID,
â”‚   â”‚   event_type VARCHAR(50), -- 'connected', 'disconnected', 'reconnected'
â”‚   â”‚   timestamp TIMESTAMP,
â”‚   â”‚   metadata JSONB
â”‚   )
â””â”€â”€ CREATE INDEX idx_heartbeats_device_time ON device_heartbeats(device_id, timestamp)

What This Solves:
â”œâ”€â”€ Proactive device issue detection
â”œâ”€â”€ Network quality monitoring
â”œâ”€â”€ Automated offline device alerts
â””â”€â”€ Historical connectivity analysis

Implementation Logic:
// Heartbeat processing
func ProcessHeartbeat(deviceID string, data HeartbeatData) {
    // Store heartbeat data
    storeHeartbeat(deviceID, data)
    
    // Check for connectivity issues
    if data.SignalStrength < SIGNAL_THRESHOLD {
        triggerLowSignalAlert(deviceID)
    }
    
    // Update device online status
    updateDeviceStatus(deviceID, "online")
    
    // Schedule offline check
    scheduleOfflineCheck(deviceID, HEARTBEAT_INTERVAL * 2)
}

Effort: 1 week
Developer: 1 Backend
```

---

## ðŸš§ Epic 7: Business Intelligence & Reporting (85% Remaining) - HIGH PRIORITY

### **Story 7.1: Comprehensive Sensor Health Dashboard**
```
As a facility manager,
I want detailed health reports for all sensors in my locations,
So that I can make data-driven decisions about maintenance and operations.
```

**Why This Is Missing:**
Currently there's no business intelligence or reporting beyond basic dashboard charts.

**What's Wrong Now:**
- Cannot generate reports for management
- No way to analyze sensor performance over time
- No maintenance scheduling based on sensor health
- Cannot compare performance across locations

**Acceptance Criteria:**
- [ ] Sensor uptime and reliability reports
- [ ] Performance trending and analysis
- [ ] Predictive maintenance recommendations
- [ ] Location and department performance comparison
- [ ] Automated health scoring for sensors

**Technical Tasks:**

**Task 7.1.1: Health Analytics Engine**
```bash
Files to Create:
â”œâ”€â”€ reporting-engine/
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ analytics/
â”‚   â”‚   â”œâ”€â”€ health_calculator.go
â”‚   â”‚   â”œâ”€â”€ trend_analyzer.go
â”‚   â”‚   â”œâ”€â”€ performance_scorer.go
â”‚   â”‚   â””â”€â”€ predictive_maintenance.go
â”‚   â”œâ”€â”€ reports/
â”‚   â”‚   â”œâ”€â”€ sensor_health_report.go
â”‚   â”‚   â”œâ”€â”€ location_comparison.go
â”‚   â”‚   â””â”€â”€ maintenance_recommendations.go
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ aggregator.go
â”‚       â”œâ”€â”€ time_series_processor.go
â”‚       â””â”€â”€ statistical_analyzer.go

Database Schema:
â”œâ”€â”€ CREATE TABLE sensor_health_scores (
â”‚   â”‚   sensor_id UUID,
â”‚   â”‚   date DATE,
â”‚   â”‚   uptime_percentage DECIMAL(5,2),
â”‚   â”‚   data_quality_score DECIMAL(5,2),
â”‚   â”‚   performance_score DECIMAL(5,2),
â”‚   â”‚   overall_health_score DECIMAL(5,2),
â”‚   â”‚   maintenance_risk VARCHAR(20)
â”‚   )
â”œâ”€â”€ CREATE TABLE performance_trends (
â”‚   â”‚   id UUID PRIMARY KEY,
â”‚   â”‚   sensor_id UUID,
â”‚   â”‚   metric_name VARCHAR(100),
â”‚   â”‚   time_period VARCHAR(20), -- 'daily', 'weekly', 'monthly'
â”‚   â”‚   trend_direction VARCHAR(20), -- 'improving', 'stable', 'declining'
â”‚   â”‚   trend_strength DECIMAL(5,2),
â”‚   â”‚   calculated_at TIMESTAMP
â”‚   )
â””â”€â”€ CREATE VIEW sensor_health_summary AS
    SELECT s.id, s.name, s.location,
           AVG(shs.overall_health_score) as avg_health,
           MAX(shs.maintenance_risk) as highest_risk
    FROM sensors s
    LEFT JOIN sensor_health_scores shs ON s.id = shs.sensor_id
    WHERE shs.date >= CURRENT_DATE - INTERVAL '30 days'
    GROUP BY s.id, s.name, s.location;

What This Solves:
â”œâ”€â”€ Objective health scoring for all sensors
â”œâ”€â”€ Trend analysis for performance optimization
â”œâ”€â”€ Predictive maintenance scheduling
â””â”€â”€ Data-driven decision making

Health Score Calculation:
```go
type HealthMetrics struct {
    UptimePercentage    float64 // % time online in period
    DataQualityScore    float64 // Valid readings / total readings
    ResponseTimeAvg     float64 // Average response time
    BatteryHealth       float64 // Battery degradation rate
    ErrorRate           float64 // Failed readings / total readings
}

func CalculateOverallHealthScore(metrics HealthMetrics) float64 {
    // Weighted scoring algorithm
    weights := map[string]float64{
        "uptime":      0.30,
        "quality":     0.25,
        "response":    0.20,
        "battery":     0.15,
        "errors":      0.10,
    }
    
    score := (metrics.UptimePercentage * weights["uptime"]) +
             (metrics.DataQualityScore * weights["quality"]) +
             ((100 - metrics.ResponseTimeAvg/10) * weights["response"]) +
             (metrics.BatteryHealth * weights["battery"]) +
             ((100 - metrics.ErrorRate) * weights["errors"])
             
    return math.Min(100, math.Max(0, score))
}
```

Effort: 1.5 weeks
Developer: 1 Backend + 1 Data Analyst
```

**Task 7.1.2: Interactive Health Dashboard**
```bash
Files to Create:
â”œâ”€â”€ origin-ui/src/components/health/
â”‚   â”œâ”€â”€ SensorHealthDashboard.tsx (NEW)
â”‚   â”œâ”€â”€ HealthScoreCard.tsx (NEW)
â”‚   â”œâ”€â”€ TrendChart.tsx (NEW)
â”‚   â”œâ”€â”€ MaintenanceSchedule.tsx (NEW)
â”‚   â”œâ”€â”€ PerformanceComparison.tsx (NEW)
â”‚   â””â”€â”€ HealthFilters.tsx (NEW)

Features to Implement:
â”œâ”€â”€ Real-time health score display
â”œâ”€â”€ Interactive trend charts
â”œâ”€â”€ Maintenance recommendation alerts
â”œâ”€â”€ Location performance heatmaps
â”œâ”€â”€ Drill-down capability from overview to sensor detail
â”œâ”€â”€ Health score history graphs

What This Solves:
â”œâ”€â”€ Visual representation of sensor health
â”œâ”€â”€ Easy identification of problem sensors
â”œâ”€â”€ Maintenance planning interface
â””â”€â”€ Executive-level performance overview

Dashboard Layout:
```tsx
const SensorHealthDashboard = () => {
  return (
    <div className="health-dashboard">
      {/* Overview Cards */}
      <div className="health-overview">
        <HealthScoreCard title="Overall Health" score={87} trend="up" />
        <HealthScoreCard title="Critical Sensors" score={3} trend="down" />
        <HealthScoreCard title="Maintenance Due" score={12} trend="stable" />
      </div>
      
      {/* Interactive Charts */}
      <div className="health-charts">
        <TrendChart 
          title="Health Trends (30 days)"
          data={healthTrendData}
          metrics={['uptime', 'quality', 'battery']}
        />
        <PerformanceComparison 
          title="Location Performance"
          data={locationComparisonData}
        />
      </div>
      
      {/* Maintenance Recommendations */}
      <MaintenanceSchedule 
        recommendations={maintenanceData}
        onSchedule={handleMaintenanceScheduling}
      />
      
      {/* Detailed Sensor List */}
      <SensorHealthTable 
        sensors={sensorHealthData}
        onDrillDown={handleSensorDrillDown}
      />
    </div>
  );
};
```

Effort: 1 week
Developer: 1 Frontend
```

---

### **Story 7.2: Comprehensive Business Reports**
```
As a business analyst,
I want to generate detailed reports about sensor operations and performance,
So that I can provide insights to management and stakeholders.
```

**Why This Is Missing:**
No way to generate formal business reports for management, compliance, or stakeholder presentations.

**What's Wrong Now:**
- Cannot export data for presentations
- No standardized report formats
- No way to schedule automatic reports
- No compliance reporting capabilities

**Acceptance Criteria:**
- [ ] PDF report generation with company branding
- [ ] CSV/Excel export for data analysis
- [ ] Scheduled report delivery via email
- [ ] Custom report templates
- [ ] Compliance reports (uptime, data quality, incidents)

**Technical Tasks:**

**Task 7.2.1: Report Generation Engine**
```bash
Files to Create:
â”œâ”€â”€ report-generator/
â”‚   â”œâ”€â”€ main.go
â”‚   â”œâ”€â”€ templates/
â”‚   â”‚   â”œâ”€â”€ sensor_performance_report.html
â”‚   â”‚   â”œâ”€â”€ compliance_report.html
â”‚   â”‚   â”œâ”€â”€ executive_summary.html
â”‚   â”‚   â””â”€â”€ maintenance_report.html
â”‚   â”œâ”€â”€ generators/
â”‚   â”‚   â”œâ”€â”€ pdf_generator.go
â”‚   â”‚   â”œâ”€â”€ excel_generator.go
â”‚   â”‚   â”œâ”€â”€ csv_generator.go
â”‚   â”‚   â””â”€â”€ template_processor.go
â”‚   â”œâ”€â”€ schedulers/
â”‚   â”‚   â”œâ”€â”€ report_scheduler.go
â”‚   â”‚   â”œâ”€â”€ email_sender.go
â”‚   â”‚   â””â”€â”€ delivery_manager.go
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ report_data_collector.go
â”‚       â”œâ”€â”€ chart_generator.go
â”‚       â””â”€â”€ table_formatter.go

Dependencies to Add:
â”œâ”€â”€ go get github.com/jung-kurt/gofpdf (PDF generation)
â”œâ”€â”€ go get github.com/360EntSecGroup-Skylar/excelize/v2 (Excel generation)
â”œâ”€â”€ go get github.com/robfig/cron/v3 (Report scheduling)

Database Schema:
â”œâ”€â”€ CREATE TABLE report_templates (
â”‚   â”‚   id UUID PRIMARY KEY,
â”‚   â”‚   name VARCHAR(255),
â”‚   â”‚   description TEXT,
â”‚   â”‚   template_type VARCHAR(50), -- 'performance', 'compliance', 'executive'
â”‚   â”‚   template_content TEXT,
â”‚   â”‚   created_by UUID,
â”‚   â”‚   created_at TIMESTAMP
â”‚   )
â”œâ”€â”€ CREATE TABLE scheduled_reports (
â”‚   â”‚   id UUID PRIMARY KEY,
â”‚   â”‚   template_id UUID,
â”‚   â”‚   name VARCHAR(255),
â”‚   â”‚   schedule_cron VARCHAR(100),
â”‚   â”‚   recipients TEXT[], -- email addresses
â”‚   â”‚   parameters JSONB,
â”‚   â”‚   is_active BOOLEAN,
â”‚   â”‚   last_generated TIMESTAMP
â”‚   )
â””â”€â”€ CREATE TABLE report_history (
â”‚       id UUID PRIMARY KEY,
â”‚       scheduled_report_id UUID,
â”‚       generated_at TIMESTAMP,
â”‚       file_path VARCHAR(500),
â”‚       file_size BIGINT,
â”‚       generation_time_ms INTEGER,
â”‚       status VARCHAR(50)
â”‚     )

What This Solves:
â”œâ”€â”€ Professional reports for management
â”œâ”€â”€ Automated compliance reporting
â”œâ”€â”€ Data export for external analysis
â””â”€â”€ Branded company reports

Example Report Generation:
```go
type ReportData struct {
    Title           string
    GeneratedAt     time.Time
    DateRange       DateRange
    LocationSummary []LocationSummary
    SensorMetrics   []SensorMetric
    Charts          []ChartData
    Recommendations []string
}

func GeneratePDFReport(template string, data ReportData) (*bytes.Buffer, error) {
    pdf := gofpdf.New("P", "mm", "A4", "")
    
    // Add company logo and branding
    addCompanyHeader(pdf)
    
    // Add report title and metadata
    addReportHeader(pdf, data.Title, data.GeneratedAt)
    
    // Add executive summary
    addExecutiveSummary(pdf, data.LocationSummary)
    
    // Add detailed metrics tables
    addMetricsTables(pdf, data.SensorMetrics)
    
    // Add charts and visualizations
    addChartsSection(pdf, data.Charts)
    
    // Add recommendations
    addRecommendations(pdf, data.Recommendations)
    
    return getPDFBuffer(pdf), nil
}
```

Effort: 2 weeks
Developer: 1 Backend
```

**Task 7.2.2: Report Builder Interface**
```bash
Files to Create:
â”œâ”€â”€ origin-ui/src/components/reports/
â”‚   â”œâ”€â”€ ReportBuilder.tsx (NEW)
â”‚   â”œâ”€â”€ TemplateEditor.tsx (NEW)
â”‚   â”œâ”€â”€ ReportScheduler.tsx (NEW)
â”‚   â”œâ”€â”€ ReportLibrary.tsx (NEW)
â”‚   â”œâ”€â”€ ReportPreview.tsx (NEW)
â”‚   â””â”€â”€ ReportHistory.tsx (NEW)

Features to Implement:
â”œâ”€â”€ Drag-and-drop report section builder
â”œâ”€â”€ Live report preview
â”œâ”€â”€ Template management system
â”œâ”€â”€ Scheduled report configuration
â”œâ”€â”€ Report history and re-generation
â”œâ”€â”€ Custom branding options

What This Solves:
â”œâ”€â”€ Non-technical users can create reports
â”œâ”€â”€ Consistent report formatting
â”œâ”€â”€ Self-service reporting capability
â””â”€â”€ Automated report distribution

Report Builder Interface:
```tsx
const ReportBuilder = () => {
  const [reportSections, setReportSections] = useState([]);
  const [selectedTemplate, setSelectedTemplate] = useState(null);
  
  return (
    <div className="report-builder">
      <div className="builder-sidebar">
        <h3>Report Sections</h3>
        <DraggableSection type="executive-summary" />
        <DraggableSection type="sensor-metrics" />
        <DraggableSection type="performance-charts" />
        <DraggableSection type="maintenance-schedule" />
        <DraggableSection type="recommendations" />
      </div>
      
      <div className="builder-canvas">
        <ReportCanvas 
          sections={reportSections}
          onSectionAdd={handleSectionAdd}
          onSectionRemove={handleSectionRemove}
          onSectionEdit={handleSectionEdit}
        />
      </div>
      
      <div className="builder-properties">
        <ReportProperties 
          template={selectedTemplate}
          onTemplateChange={handleTemplateChange}
        />
        <ReportScheduling 
          onScheduleUpdate={handleScheduleUpdate}
        />
      </div>
      
      <div className="builder-actions">
        <button onClick={handlePreview}>Preview Report</button>
        <button onClick={handleGenerate}>Generate Report</button>
        <button onClick={handleSaveTemplate}>Save Template</button>
      </div>
    </div>
  );
};
```

Effort: 2 weeks
Developer: 1 Frontend + 1 Backend
```

---

## ðŸ§ª Cross-Cutting: Testing & Quality Assurance (75% Remaining)

### **Story QA.1: Comprehensive Testing Framework**
```
As a development team lead,
I want comprehensive automated testing across all services,
So that we can deploy confidently and maintain code quality.
```

**Why This Is Missing:**
Currently no automated testing framework exists, making deployments risky and code quality uncertain.

**What's Wrong Now:**
- No unit tests for Go services
- No integration tests between services
- No frontend component testing
- Manual testing only, which is error-prone and slow

**Acceptance Criteria:**
- [ ] 80% code coverage across all Go services
- [ ] Unit tests for all React components
- [ ] Integration tests for service communication
- [ ] End-to-end tests for critical workflows
- [ ] Automated test execution in CI/CD

**Technical Tasks:**

**Task QA.1.1: Go Services Unit Testing**
```bash
Files to Create (Per Service):
â”œâ”€â”€ account-manager/
â”‚   â”œâ”€â”€ handlers_test.go
â”‚   â”œâ”€â”€ business_logic_test.go
â”‚   â”œâ”€â”€ validation_test.go
â”‚   â””â”€â”€ integration_test.go

â”œâ”€â”€ device-ingress/
â”‚   â”œâ”€â”€ ingestion_test.go
â”‚   â”œâ”€â”€ data_processing_test.go
â”‚   â”œâ”€â”€ api_handlers_test.go
â”‚   â””â”€â”€ integration_test.go

â”œâ”€â”€ alert-listener/
â”‚   â”œâ”€â”€ alert_processing_test.go
â”‚   â”œâ”€â”€ notification_test.go
â”‚   â”œâ”€â”€ rule_engine_test.go
â”‚   â””â”€â”€ integration_test.go

Testing Framework Setup:
â”œâ”€â”€ go.mod: Add testing dependencies
â”‚   â”œâ”€â”€ github.com/stretchr/testify
â”‚   â”œâ”€â”€ github.com/DATA-DOG/go-sqlmock
â”‚   â”œâ”€â”€ github.com/golang/mock
â”‚   â””â”€â”€ github.com/onsi/ginkgo/v2

â”œâ”€â”€ Makefile: Add test commands
â”‚   â”œâ”€â”€ test: Run all unit tests
â”‚   â”œâ”€â”€ test-integration: Run integration tests
â”‚   â”œâ”€â”€ test-coverage: Generate coverage reports
â”‚   â””â”€â”€ test-bench: Run benchmark tests

Example Test Implementation:
```go
// account-manager/handlers_test.go
func TestCreateSubsidiary(t *testing.T) {
    // Setup
    db, mock, err := sqlmock.New()
    require.NoError(t, err)
    defer db.Close()
    
    handler := &SubsidiaryHandler{db: db}
    
    // Test cases
    tests := []struct {
        name           string
        input          CreateSubsidiaryRequest
        mockSetup      func()
        expectedStatus int
        expectedError  string
    }{
        {
            name: "Valid subsidiary creation",
            input: CreateSubsidiaryRequest{
                Name:    "Test Corp",
                Address: "123 Test St",
                Contact: "test@test.com",
            },
            mockSetup: func() {
                mock.ExpectExec("INSERT INTO subsidiaries").
                    WithArgs("Test Corp", "123 Test St", "test@test.com").
                    WillReturnResult(sqlmock.NewResult(1, 1))
            },
            expectedStatus: 201,
        },
        {
            name: "Invalid email format",
            input: CreateSubsidiaryRequest{
                Name:    "Test Corp",
                Address: "123 Test St",
                Contact: "invalid-email",
            },
            expectedStatus: 400,
            expectedError:  "invalid email format",
        },
    }
    
    // Execute tests
    for _, tt := range tests {
        t.Run(tt.name, func(t *testing.T) {
            if tt.mockSetup != nil {
                tt.mockSetup()
            }
            
            // Create request
            reqBody, _ := json.Marshal(tt.input)
            req := httptest.NewRequest("POST", "/subsidiaries", bytes.NewBuffer(reqBody))
            w := httptest.NewRecorder()
            
            // Execute
            handler.CreateSubsidiary(w, req)
            
            // Assert
            assert.Equal(t, tt.expectedStatus, w.Code)
            if tt.expectedError != "" {
                assert.Contains(t, w.Body.String(), tt.expectedError)
            }
        })
    }
}
```

Coverage Requirements by Service:
â”œâ”€â”€ account-manager: 85% (critical business logic)
â”œâ”€â”€ device-ingress: 80% (data processing)
â”œâ”€â”€ alert-listener: 85% (critical notifications)
â”œâ”€â”€ sso: 90% (security critical)
â”œâ”€â”€ data-manager: 75% (data transformation)
â””â”€â”€ golioth-integration: 80% (new critical component)

Effort: 3 weeks
Developer: 2 Backend + 1 DevOps
```

**Task QA.1.2: Frontend Component Testing**
```bash
Files to Create:
â”œâ”€â”€ origin-ui/src/components/__tests__/
â”‚   â”œâ”€â”€ UnifiedDashboard.test.tsx
â”‚   â”œâ”€â”€ SensorCard.test.tsx
â”‚   â”œâ”€â”€ AlertPanel.test.tsx
â”‚   â”œâ”€â”€ SensorAnalytics.test.tsx
â”‚   â””â”€â”€ MetricCard.test.tsx

â”œâ”€â”€ origin-ui/src/utils/__tests__/
â”‚   â”œâ”€â”€ mockDataGenerators.test.ts
â”‚   â”œâ”€â”€ formatters.test.ts
â”‚   â””â”€â”€ validators.test.ts

Testing Setup:
â”œâ”€â”€ package.json: Add testing dependencies
â”‚   â”œâ”€â”€ @testing-library/react
â”‚   â”œâ”€â”€ @testing-library/jest-dom
â”‚   â”œâ”€â”€ @testing-library/user-event
â”‚   â”œâ”€â”€ jest-environment-jsdom
â”‚   â””â”€â”€ msw (for API mocking)

â”œâ”€â”€ jest.config.js: Configure Jest
â”œâ”€â”€ setupTests.ts: Global test setup
â””â”€â”€ __mocks__/: Mock implementations

Example Component Test:
```tsx
// UnifiedDashboard.test.tsx
describe('UnifiedDashboard', () => {
  const mockSensors = [
    {
      id: '1',
      name: 'Temperature Sensor',
      type: 'temperature',
      status: 'online' as const,
      value: 22.5,
      unit: 'Â°C',
      location: 'Room 101'
    }
  ];

  beforeEach(() => {
    // Mock API calls
    server.use(
      rest.get('/api/sensors', (req, res, ctx) => {
        return res(ctx.json({ sensors: mockSensors }));
      })
    );
  });

  it('renders sensor data correctly', async () => {
    render(<UnifiedDashboard mode="demo" />);
    
    // Wait for data to load
    await waitFor(() => {
      expect(screen.getByText('Temperature Sensor')).toBeInTheDocument();
    });
    
    // Check sensor value display
    expect(screen.getByText('22.5Â°C')).toBeInTheDocument();
    
    // Check status badge
    expect(screen.getByText('online')).toBeInTheDocument();
    expect(screen.getByText('online')).toHaveClass('status-online');
  });

  it('handles sensor click for analytics', async () => {
    const user = userEvent.setup();
    render(<UnifiedDashboard mode="demo" />);
    
    await waitFor(() => {
      expect(screen.getByText('Temperature Sensor')).toBeInTheDocument();
    });
    
    // Click on sensor
    await user.click(screen.getByText('Temperature Sensor'));
    
    // Check if analytics panel opens
    expect(screen.getByText('Sensor Analytics')).toBeInTheDocument();
    expect(screen.getByText('Recent Readings')).toBeInTheDocument();
  });

  it('switches between demo and production modes', () => {
    const { rerender } = render(<UnifiedDashboard mode="demo" />);
    
    // Check demo mode elements
    expect(screen.getByText('Analytics')).toBeInTheDocument();
    
    // Switch to production mode
    rerender(<UnifiedDashboard mode="production" />);
    
    // Analytics tab should not be visible in production
    expect(screen.queryByText('Analytics')).not.toBeInTheDocument();
  });
});
```

Test Coverage Requirements:
â”œâ”€â”€ Components: 80% line coverage
â”œâ”€â”€ Utilities: 90% line coverage
â”œâ”€â”€ Hooks: 85% line coverage
â”œâ”€â”€ Integration: 70% line coverage

Effort: 2 weeks
Developer: 1 Frontend + 1 QA
```

**Task QA.1.3: Integration & E2E Testing**
```bash
Files to Create:
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ integration/
â”‚   â”‚   â”œâ”€â”€ auth_flow_test.go
â”‚   â”‚   â”œâ”€â”€ device_management_test.go
â”‚   â”‚   â”œâ”€â”€ data_pipeline_test.go
â”‚   â”‚   â””â”€â”€ notification_flow_test.go
â”‚   â”œâ”€â”€ e2e/
â”‚   â”‚   â”œâ”€â”€ user_onboarding.spec.ts
â”‚   â”‚   â”œâ”€â”€ sensor_management.spec.ts
â”‚   â”‚   â”œâ”€â”€ alert_configuration.spec.ts
â”‚   â”‚   â””â”€â”€ report_generation.spec.ts
â”‚   â””â”€â”€ load/
â”‚       â”œâ”€â”€ sensor_data_load_test.js
â”‚       â”œâ”€â”€ api_performance_test.js
â”‚       â””â”€â”€ dashboard_load_test.js

Tools Setup:
â”œâ”€â”€ Playwright: For E2E testing
â”œâ”€â”€ k6: For load testing
â”œâ”€â”€ Testcontainers: For integration testing
â”œâ”€â”€ Docker Compose: Test environment

Example Integration Test:
```go
// integration/device_management_test.go
func TestDeviceManagementFlow(t *testing.T) {
    // Setup test environment
    testDB := setupTestDatabase()
    defer testDB.Close()
    
    testServices := startTestServices(testDB)
    defer testServices.Stop()
    
    client := &APIClient{BaseURL: testServices.APIEndpoint}
    
    t.Run("Complete device lifecycle", func(t *testing.T) {
        // 1. Create subsidiary
        subsidiary := createTestSubsidiary(t, client)
        
        // 2. Create location
        location := createTestLocation(t, client, subsidiary.ID)
        
        // 3. Provision device
        device := provisionTestDevice(t, client, location.ID)
        
        // 4. Verify device appears in dashboard
        sensors := getSensors(t, client, location.ID)
        require.Len(t, sensors, 1)
        assert.Equal(t, device.ID, sensors[0].DeviceID)
        
        // 5. Simulate sensor data
        sendTestSensorData(t, client, device.ID)
        
        // 6. Verify data appears in dashboard
        readings := getSensorReadings(t, client, sensors[0].ID)
        require.NotEmpty(t, readings)
        
        // 7. Test alert trigger
        sendAlertThresholdData(t, client, device.ID)
        
        // 8. Verify alert generated
        alerts := getAlerts(t, client, location.ID)
        require.Len(t, alerts, 1)
        assert.Equal(t, "critical", alerts[0].Severity)
    })
}
```

Example E2E Test:
```typescript
// e2e/sensor_management.spec.ts
test.describe('Sensor Management', () => {
  test('complete sensor configuration workflow', async ({ page }) => {
    // Login
    await page.goto('/login');
    await page.fill('[data-testid=email]', 'admin@test.com');
    await page.fill('[data-testid=password]', 'password123');
    await page.click('[data-testid=login-button]');
    
    // Navigate to sensors page
    await page.click('[data-testid=sensors-nav]');
    await expect(page).toHaveURL('/sensors');
    
    // Add new sensor
    await page.click('[data-testid=add-sensor-button]');
    await page.fill('[data-testid=sensor-name]', 'Test Temperature Sensor');
    await page.selectOption('[data-testid=sensor-type]', 'temperature');
    await page.fill('[data-testid=sensor-location]', 'Room 101');
    await page.click('[data-testid=save-sensor]');
    
    // Verify sensor appears in list
    await expect(page.locator('[data-testid=sensor-list]')).toContainText('Test Temperature Sensor');
    
    // Configure alerts
    await page.click('[data-testid=configure-alerts]');
    await page.fill('[data-testid=high-threshold]', '30');
    await page.fill('[data-testid=low-threshold]', '10');
    await page.click('[data-testid=save-alerts]');
    
    // Verify configuration saved
    await expect(page.locator('[data-testid=success-message]')).toBeVisible();
  });
});
```

Test Environment Setup:
â”œâ”€â”€ Docker Compose test stack
â”œâ”€â”€ Test data seeding scripts
â”œâ”€â”€ CI/CD integration
â”œâ”€â”€ Performance benchmarks

Effort: 2.5 weeks
Developer: 1 DevOps + 1 QA Engineer
```

---

## ðŸ“… **Summary: Total Effort Estimation**

### **By Epic Priority:**
```
Epic 2 (Golioth Integration) - CRITICAL
â”œâ”€â”€ Task 2.1.1: Golioth SDK Integration (1 week, 1 senior backend)
â”œâ”€â”€ Task 2.1.2: Device Provisioning (1 week, 1 backend + 1 frontend)
â”œâ”€â”€ Task 2.1.3: LightDB Stream Integration (1.5 weeks, 2 backend)
â”œâ”€â”€ Task 2.2.1: Pipeline Configuration Engine (2 weeks, 1 senior backend)
â”œâ”€â”€ Task 2.2.2: Visual Pipeline Editor (2 weeks, 1 frontend + 1 backend)
â”œâ”€â”€ Task 2.3.1: Device Health Monitoring (1 week, 1 backend)
â””â”€â”€ Total: 8.5 weeks effort, 3-4 weeks with parallel development

Epic 7 (Business Intelligence) - HIGH PRIORITY
â”œâ”€â”€ Task 7.1.1: Health Analytics Engine (1.5 weeks, 1 backend + 1 data analyst)
â”œâ”€â”€ Task 7.1.2: Interactive Health Dashboard (1 week, 1 frontend)
â”œâ”€â”€ Task 7.2.1: Report Generation Engine (2 weeks, 1 backend)
â”œâ”€â”€ Task 7.2.2: Report Builder Interface (2 weeks, 1 frontend + 1 backend)
â””â”€â”€ Total: 6.5 weeks effort, 2-3 weeks with parallel development

Cross-Cutting QA - HIGH PRIORITY
â”œâ”€â”€ Task QA.1.1: Go Services Unit Testing (3 weeks, 2 backend + 1 DevOps)
â”œâ”€â”€ Task QA.1.2: Frontend Component Testing (2 weeks, 1 frontend + 1 QA)
â”œâ”€â”€ Task QA.1.3: Integration & E2E Testing (2.5 weeks, 1 DevOps + 1 QA)
â””â”€â”€ Total: 7.5 weeks effort, 3-4 weeks with parallel development

All Other Epics (1,3,4,5,6) - MEDIUM PRIORITY
â””â”€â”€ Total: 3 weeks effort, 2 weeks with parallel development
```

### **Recommended Team & Timeline:**
```
Team Composition:
â”œâ”€â”€ 1 Senior Backend Developer (IoT/Golioth expertise)
â”œâ”€â”€ 2 Backend Developers
â”œâ”€â”€ 1 Frontend Developer
â”œâ”€â”€ 1 DevOps Engineer
â”œâ”€â”€ 1 QA Engineer
â””â”€â”€ 1 Data Analyst (part-time)

Timeline: 6-8 weeks total
â”œâ”€â”€ Weeks 1-4: Golioth Integration (Critical Path)
â”œâ”€â”€ Weeks 3-6: Business Intelligence (Parallel)
â”œâ”€â”€ Weeks 5-8: Testing & Quality Assurance (Parallel)
â””â”€â”€ Weeks 7-8: Final Integration & Validation
```

This detailed breakdown provides you with specific, actionable tasks that can be assigned to developers, estimated, and tracked. Each task has clear deliverables, acceptance criteria, and implementation details.
